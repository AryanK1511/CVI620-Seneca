{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## OpenCV\n",
    "import numpy\n",
    "import matplotlib\n",
    "import cv2 as cv\n",
    "\n",
    "image=cv.imread('./Pizza.jpg')\n",
    "\n",
    "# Using namedWindow() \n",
    "# A window with 'Display' name is created \n",
    "# with WINDOW_AUTOSIZE, window size is set automatically \n",
    "cv.namedWindow(\"Pizza\", cv.WINDOW_AUTOSIZE) \n",
    "\n",
    "image=cv.resize(image, (600,400))\n",
    "\n",
    "# using cv2.imshow() to display the image \n",
    "cv.imshow('Pizza', image) \n",
    "  \n",
    "# Waiting 0ms for user to press any key (It will wait forever until user press any key)\n",
    "cv.waitKey(0) \n",
    "  \n",
    "# Using cv2.destroyAllWindows() to destroy \n",
    "# all created windows open on screen \n",
    "cv.destroyAllWindows() \n",
    "\n",
    "## video Capture\n",
    "\n",
    "# Start a video capture, using device's camera\n",
    "webcam= cv.VideoCapture(1)\n",
    "\n",
    "stop = False\n",
    "while stop == False:\n",
    "    ret,frame = webcam.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        cv.imshow('Pizza',frame)\n",
    "        key = cv.waitKey(1) \n",
    "        if key == ord(\"q\"):\n",
    "            stop = True\n",
    "webcam.release()\n",
    "cv.destroyAllWindows()\n",
    "## Graphs for Categorical Data\n",
    "### Graphs for Categorical Data\n",
    "### A Statistical Table is a list of the categories being considered along with a measure of how often each value occurred.\n",
    "#### Graphs for Categorical Data\n",
    "#### Ways to measure “how often” each value has occurred:\n",
    "#### 1.Frequency\n",
    "#### 2. Relative frequency\n",
    "#### 3.Percentage\n",
    "### Types of Graphs for Categorical Data\n",
    "#### 1. Bar charts\n",
    "#### 2. Pie charts\n",
    "### Example: In a survey concerning public education, 400 school administrators were asked to rate the quality of education on a graded scale from “A” to “D”.\n",
    "### Rating Frequency\n",
    "##### A 35\n",
    "##### B 260\n",
    "##### C 93\n",
    "##### D 12\n",
    "##### Total 400\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grades=('A', 'B', 'C', 'D')\n",
    "frequency=[35,260,93,12]\n",
    "plt.bar(grades, frequency)\n",
    "plt.show()\n",
    "grades = [\"A\", \"B\",\"C\",\"D\"]\n",
    "frequency = [ 35,260, 93,12]\n",
    "plt.bar(grades,frequency)\n",
    "plt.title(\"Quality of Education\")\n",
    "plt.xlabel(\"Graded Scale\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "plt.pie(frequency, labels=grades)\n",
    "plt.title(\"Quality of Education\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "labels = [\"Apples\", \"Bananas\", \"Cherries\", \"Dates\"]\n",
    "Numbers = [35,25,25,15]\n",
    "plt.pie(Numbers , labels = labels, startangle = 45)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "### Explode\n",
    "#### Maybe you want one of the wedges to stand out? The explode parameter allows you to do that.\n",
    "\n",
    "#### The explode parameter, if specified, and not None, must be an array with one value for each wedge.\n",
    "\n",
    "#### Each value represents how far from the center each wedge is displayed:\n",
    "Explode=[0,0,0,0.05]\n",
    "plt.pie(Numbers , labels = labels, explode = Explode ,startangle = 25)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "### Shadow\n",
    "#### Add a shadow to the pie chart by setting the shadows parameter to True:\n",
    "\n",
    "plt.pie(Numbers , labels = labels, startangle = 0,explode = Explode , shadow = True )\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#### Colors\n",
    "###### You can set the color of each wedge with the colors parameter.\n",
    "\n",
    "###### The colors parameter, if specified, must be an array with one value for each wedge:\n",
    "### 'r' - Red\n",
    "#### 'g' - Green\n",
    "#### 'b' - Blue\n",
    "#### 'c' - Cyan\n",
    "#### 'm' - Magenta\n",
    "#### 'y' - Yellow\n",
    "#### 'k' - Black\n",
    "#### 'w' - White\n",
    "\n",
    "\n",
    "labels = [\"Apples\", \"Bananas\", \"Cherries\", \"Dates\"]\n",
    "Numbers = [35,25,25,15]\n",
    "Explode = [0,0,0,0.2]\n",
    "colors = [\"r\" , \"y\",\"b\", \"k\"]\n",
    "plt.pie(Numbers , labels = labels, startangle = 20 ,explode = Explode , shadow = True ,colors = colors)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "### Legend With Header\n",
    "#### To add a header to the legend, add the title parameter to the legend function.\n",
    "\n",
    "labels = [\"Apples\", \"Bananas\", \"Cherries\", \"Dates\"]\n",
    "Numbers = [35,25,25,15]\n",
    "Explode = [0,0,0,0.1]\n",
    "colors = [\"r\" , \"y\",\"b\", \"k\"]\n",
    "plt.pie(Numbers , labels = labels, startangle = 25,explode = Explode , shadow = True ,colors = colors)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend(title = \"Fruites: \")\n",
    "plt.show()\n",
    "### How to Change the Position of a Legend in Matplotlib\n",
    "### locations:\n",
    "\n",
    "### upper right\n",
    "### upper left\n",
    "### lower left\n",
    "### lower right\n",
    "### right\n",
    "### center left\n",
    "### center right\n",
    "### lower center\n",
    "### upper center\n",
    "### center\n",
    "labels = [\"Apples\", \"Bananas\", \"Cherries\", \"Dates\"]\n",
    "Numbers = [35,25,25,15]\n",
    "Explode = [0,0,0,0.2]\n",
    "colors = [\"r\" , \"y\",\"b\", \"k\"]\n",
    "plt.pie(Numbers , labels = labels, startangle = 0,explode = Explode , shadow = True ,colors = colors)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend(bbox_to_anchor = (0.9,1),title = \"Four Fruites :\")\n",
    "plt.show()\n",
    "# Change Legend Position Outside of Matplotlib Plot\n",
    "##### To place the legend outside of a Matplotlib plot, we can use the bbox_to_anchor() argument.\n",
    "labels = [\"Apples\", \"Bananas\", \"Cherries\", \"Dates\"]\n",
    "Numbers = [35,25,25,15]\n",
    "Explode = [0,0,0,0.2]\n",
    "colors = [\"r\" , \"y\",\"b\", \"k\"]\n",
    "plt.pie(Numbers , labels = labels, startangle = 0,explode = Explode , shadow = True ,colors = colors)\n",
    "plt.title(\"Fruits\")\n",
    "plt.legend(title = \"Four fruits :\", loc = \"upper right\")\n",
    "plt.show()\n",
    "## Scatter\n",
    "x = [5,7,8,5,6,7,9,2,3,4,4,4,2,6,3,6,8,6,4,7]\n",
    "y = [7,4,3,9,1,3,2,5,2,4,8,7,1,6,4,9,7,7,5,1]\n",
    "plt.scatter(x,y , color = \"r\" , edgecolor = \"k\" , linewidth = 1 , alpha = 1)\n",
    "plt.show()\n",
    "### line plot\n",
    "x=[3,7,8,9]\n",
    "plt.plot(x)\n",
    "##Use a dashed line and marker:\n",
    "plt.plot(x, linestyle = \"dashed\", marker='h')\n",
    "plt.show()\n",
    "# Add Grid lines to plot\n",
    "x = [80, 85, 90, 95, 100, 105, 110, 115, 120, 125]\n",
    "y =[240, 250, 260, 270, 280, 290, 300, 310, 320,335]\n",
    "plt.plot(x,y , color = \"b\" , marker = \"o\",linestyle = \"dashed\" )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "### Display Multiple Plots\n",
    "#### With the subplot() function you can draw multiple plots in one figure:\n",
    "\n",
    "# plot 1\n",
    "x = [0, 1, 2, 3]\n",
    "y =  [3, 8, 1, 10]\n",
    "plt.figure(figsize=(3,8))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x,y)\n",
    "\n",
    "# plot 2\n",
    "x = [0, 1, 2, 3]\n",
    "y =  [10,20,30,40]\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x,y)\n",
    "\n",
    "# plot 3 \n",
    "x = [0, 1, 2, 3]\n",
    "y =  [100,200,300,400]\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./company_sales_data.csv\")\n",
    "data.head(2)\n",
    "data.describe().T\n",
    "def profit(abc):\n",
    "    if abc >= 200000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "data[\"class\"] = data[\"total_profit\"].apply(profit)\n",
    "data.head(2)\n",
    "data[\"total_number of unit\"] = data[\"facecream\"] + data[\"facewash\"] + data[\"toothpaste\"] + data[\"bathingsoap\"] + data[\"shampoo\"] + data[\"moisturizer\"]\n",
    "data.head(2)\n",
    "data.iloc[:,0]\n",
    "### Get total profit of all months and show line plot with the following Style properties\n",
    "####  Line Style dotted and Line-color should be red\n",
    "### Show legend at the lower right location.\n",
    "### X label name = Month Number\n",
    "### Y label name = total profit\n",
    "### Add a circle marker.\n",
    "### Line marker color as black\n",
    "### Line width should be 3\n",
    "data.columns\n",
    "data[\"month_number\"]\n",
    "x = data[\"month_number\"]\n",
    "x\n",
    "y = data[\"total_profit\"]\n",
    "y\n",
    "\n",
    "\n",
    "plt.plot(x,y, label = \"total_profit\",linewidth = 3,marker = \"o\",linestyle =\"--\")\n",
    "plt.legend(loc= \"lower right\")\n",
    "plt.xlabel(\"month number\")\n",
    "plt.ylabel(\"total profit\")\n",
    "plt.show()\n",
    "## Read all product sales data and show it  using a multiline plot\n",
    "#### Display the number of units sold per month for each product using multiline plots. (i.e., Separate Plotline for each product ).\n",
    "data.columns\n",
    "data[\"month_number\"]\n",
    "data[\"facecream\"]\n",
    "x = data[\"month_number\"]\n",
    "y1 = data[\"facecream\"]\n",
    "y2 = data[\"facewash\"]\n",
    "plt.plot(x,y1, label = \"face cream sales data\",marker = \"o\",linewidth = 2,linestyle =\"--\")\n",
    "plt.plot(x,y2, label = \"face wash sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.legend(loc= \"upper left\")\n",
    "plt.xlabel(\"month number\")\n",
    "plt.ylabel(\" Sales units in number\")\n",
    "plt.show()\n",
    "x = data[\"month_number\"]\n",
    "y1 = data[\"facecream\"]\n",
    "y2 = data[\"facewash\"]\n",
    "y3= data[\"toothpaste\"]\n",
    "y4= data[\"bathingsoap\"]\n",
    "y5= data[\"shampoo\"]\n",
    "y6 = data[\"moisturizer\"]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x,y1, label = \"face cream sales data\",marker = \"o\",linewidth = 2,linestyle =\"--\")\n",
    "plt.plot(x,y2, label = \"face wash sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.plot(x,y3, label = \"tooth paste sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.plot(x,y4, label = \"bathing soap sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.plot(x,y5, label = \"shampoo sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.plot(x,y6, label = \"moisturizer sales data\",marker = \"o\",linewidth = 2)\n",
    "plt.legend(loc= \"upper left\")\n",
    "plt.xlabel(\"month number\")\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\" Sales units in number\")\n",
    "plt.show()\n",
    "## Read toothpaste sales data of each month and show it using a scatter plot\n",
    "####  also, add a grid in the plot. gridline style should “–“.\n",
    "y7 = data[\"toothpaste\"]\n",
    "x = data[\"month_number\"]\n",
    "plt.scatter(x,y7,label = \"Tooth paste Sales data\",color = \"black\")\n",
    "plt.xlabel(\"Month Number\")\n",
    "plt.ylabel(\"Number of unit sold\")\n",
    "plt.title(\"tooth paste Sales Data\")\n",
    "plt.legend(loc= \"upper left\")\n",
    "plt.xticks(x)\n",
    "plt.grid(True, linewidth = 1 , linestyle = \"--\")\n",
    "plt.show()\n",
    "\n",
    "### Read face cream and facewash product sales data and show it using the bar chart\n",
    "plt.bar( x,data[\"facewash\"], edgecolor = \"k\")\n",
    "plt.title(\"face cream sales data\")\n",
    "plt.xlabel(\"face wash sales data\")\n",
    "plt.ylabel(\"sales unit number\")\n",
    "plt.xlabel(\"months\")\n",
    "plt.xticks(x)\n",
    "plt.show()\n",
    "### Read sales data of bathing soap of all months and show it using a bar chart. Save this plot to your hard disk\n",
    "monthList = data[\"month_number\"]\n",
    "bathingsoapSalesData = data[\"bathingsoap\"]\n",
    "plt.bar(monthList,bathingsoapSalesData,label = \"Tooth paste Sales data\",color = \"black\")\n",
    "plt.xlabel(\"Month Number\")\n",
    "plt.ylabel(\"Number of unit sold\")\n",
    "plt.title(\"bathing soap Sales Data\")\n",
    "plt.legend(loc= \"upper left\")\n",
    "plt.xticks(monthList)\n",
    "plt.grid(True, linewidth = 1 , linestyle = \"--\")\n",
    "plt.savefig(\"bar chart.png\" )\n",
    "plt.show()\n",
    "### Read the total profit of each month and show it using the histogram to see the most common profit ranges\n",
    "### Calculate total sale data for last year for each product and show it using a Pie chart\n",
    "### Read Bathing soap facewash of all months and display it using the Subplot\n",
    "### Read all product sales data and show it using the stack plot\n",
    "data = pd.read_csv(\"./company_sales_data.csv\")\n",
    "plt.plot(data[\"month_number\"], data[\"total_profit\"], label = \"total_profit\",linewidth = 3,marker = \"o\",linestyle =\"--\", color=\"red\")\n",
    "plt.plot(data[\"month_number\"], data[\"facewash\"], label = \"face_cream\",marker = \"o\", linewidth = 3)\n",
    "plt.legend(loc= \"lower right\")\n",
    "plt.xlabel(\"month number\")\n",
    "plt.ylabel(\"total profit\")\n",
    "plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as img \n",
    "import cv2\n",
    "bsz=50\n",
    "image=cv2.imread('./Pizza.jpg')\n",
    "image_2=cv2.resize(image, (800,400))\n",
    "cv2.imshow('Image', image_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "img1=img.imread('./Pizza.jpg')\n",
    "\n",
    "plt.imshow(img1) \n",
    "\n",
    "# displaying the shape of the image \n",
    "print(img1.shape)\n",
    "## Example 3: Here, the shape of the image is (225, 225, 3) which represents (height, width, mode) of the image, for colored image mode value is from 0 to 2 and for black and white image mode value is 0 and 1 only. In the output image, only the mode of the image is modified.\n",
    "# modifying the shape of the image \n",
    "modifiedImage = img1[:, :, 2] \n",
    "  \n",
    "# displaying the modified image \n",
    "plt.imshow(modifiedImage) \n",
    "# modifying the shape of the image \n",
    "modifiedImage = img1[0:1600,1000:2000, 1] \n",
    "  \n",
    "# displaying the modified image \n",
    "plt.imshow(modifiedImage) \n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "## OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "#### cv2.copyMakeBorder() method is used to create a border around the image like a photo frame. \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as img \n",
    "import cv2\n",
    "bsz=50\n",
    "image=cv2.imread('./Pizza.jpg')\n",
    "image_2=cv2.resize(image, (800,400))\n",
    "cv2.imshow('Image', image_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "img1=img.imread('./Pizza.jpg')\n",
    "\n",
    "plt.imshow(img1) \n",
    "\n",
    "# displaying the shape of the image \n",
    "print(img1.shape)\n",
    "## Example 3: Here, the shape of the image is (225, 225, 3) which represents (height, width, mode) of the image, for colored image mode value is from 0 to 2 and for black and white image mode value is 0 and 1 only. In the output image, only the mode of the image is modified.\n",
    "# modifying the shape of the image \n",
    "modifiedImage = img1[:, :, 2] \n",
    "  \n",
    "# displaying the modified image \n",
    "plt.imshow(modifiedImage) \n",
    "# modifying the shape of the image \n",
    "modifiedImage = img1[0:1600,1000:2000, 1] \n",
    "  \n",
    "# displaying the modified image \n",
    "plt.imshow(modifiedImage) \n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "## OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "#### cv2.copyMakeBorder() method is used to create a border around the image like a photo frame. \n",
    "outputImage = cv2.copyMakeBorder(\n",
    "                                    inputImage, \n",
    "                                    topBorderWidth, \n",
    "                                    bottomBorderWidth, \n",
    "                                    leftBorderWidth, \n",
    "                                    rightBorderWidth, \n",
    "                                    cv2.BORDER_CONSTANT, \n",
    "                                     value=color of border\n",
    "                                 )\n",
    "\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT)\n",
    "plt.imshow(constant)\n",
    "# The cv2.BORDER_CONSTANT adds a constant colored border to the image. \n",
    "# The color of the border can be passed as an optional parameter called value. Otherwise, a plain black colored border is created.\n",
    "BLUE=[255,0,0]\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT,value = BLUE)\n",
    "plt.imshow(constant)\n",
    "from random import randint\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT,value = [randint(0, 255), randint(0, 255), randint(0, 255)])\n",
    "plt.imshow(constant)\n",
    "# Using cv2.cvtColor() method\n",
    "# Using cv2.COLOR_BGR2GRAY color space\n",
    "# conversion code\n",
    "plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "# Using cv2.cvtColor() method\n",
    "# Using cv2.COLOR_BGR2HSV color space\n",
    "# conversion code\n",
    "plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2HSV))\n",
    "plt.show()\n",
    "# Convert from BGR to Grayscale\n",
    "gray_image = plt.imshow(cv.cvtColor(img1, cv.COLOR_BGR2GRAY))\n",
    "gray_image\n",
    "## The cv2.BORDER_REFLECT creates borders which is a mirror reflection of border elements like this:\n",
    "img = cv.imread(\"C:\\\\Users\\\\Savita Seharawat\\\\Desktop\\\\cvi620\\\\week 2\\\\project.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "REFLECT=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_REFLECT)\n",
    "plt.imshow(REFLECT)\n",
    "plt.show()\n",
    "\n",
    "REPLICATE=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_REPLICATE)\n",
    "plt.imshow(REPLICATE)\n",
    "plt.show()\n",
    "WRAP=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_WRAP)\n",
    "plt.imshow(WRAP)\n",
    "plt.show()\n",
    "REFLECT=cv.copyMakeBorder(img1,550,550,550,550,cv.BORDER_REFLECT)\n",
    "plt.imshow(REFLECT)\n",
    "plt.show()\n",
    "WRAP=cv.copyMakeBorder(img1,550,550,550,550,cv.BORDER_WRAP)\n",
    "plt.imshow(WRAP)\n",
    "plt.show()\n",
    "\n",
    "replicate=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REPLICATE)\n",
    "reflect=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REFLECT)\n",
    "reflect101=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REFLECT_101)\n",
    "wrap=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_WRAP)\n",
    "constant=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_CONSTANT,value=BLUE)\n",
    "plt.subplot(231), plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2RGB)), plt.title('ORIGINAL')\n",
    "plt.subplot(232), plt.imshow(cv.cvtColor(replicate,cv.COLOR_BGR2RGB)), plt.title('REPLICATE')\n",
    "plt.subplot(233), plt.imshow(cv.cvtColor(reflect,cv.COLOR_BGR2RGB)), plt.title('REFLECT')\n",
    "plt.subplot(234), plt.imshow(cv.cvtColor(reflect101,cv.COLOR_BGR2RGB)), plt.title('REFLECT_101')\n",
    "plt.subplot(235), plt.imshow(cv.cvtColor(wrap,cv.COLOR_BGR2RGB)), plt.title('WRAP')\n",
    "plt.subplot(236), plt.imshow(cv.cvtColor(constant,cv.COLOR_BGR2RGB)), plt.title('CONSTANT')\n",
    "plt.show()\n",
    "\n",
    "image = cv.imread(\"C:\\\\Users\\\\Savita Seharawat\\\\Desktop\\\\cvi620\\\\week 2\\\\cmyk_paint.png\") \n",
    "B, G, R = cv.split(image) \n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(image) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(B) \n",
    "plt.title(\"blue\")\n",
    "plt.show()\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(G) \n",
    "plt.title(\"Green\")\n",
    "plt.show()\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(R) \n",
    "plt.title(\"Red\")\n",
    "plt.show()\n",
    "outputImage = cv2.copyMakeBorder(\n",
    "                                    inputImage, \n",
    "                                    topBorderWidth, \n",
    "                                    bottomBorderWidth, \n",
    "                                    leftBorderWidth, \n",
    "                                    rightBorderWidth, \n",
    "                                    cv2.BORDER_CONSTANT, \n",
    "                                     value=color of border\n",
    "                                 )\n",
    "\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT)\n",
    "plt.imshow(constant)\n",
    "# The cv2.BORDER_CONSTANT adds a constant colored border to the image. \n",
    "# The color of the border can be passed as an optional parameter called value. Otherwise, a plain black colored border is created.\n",
    "BLUE=[255,0,0]\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT,value = BLUE)\n",
    "plt.imshow(constant)\n",
    "from random import randint\n",
    "constant=cv.copyMakeBorder(img1,0,0,50,50,cv.BORDER_CONSTANT,value = [randint(0, 255), randint(0, 255), randint(0, 255)])\n",
    "plt.imshow(constant)\n",
    "# Using cv2.cvtColor() method\n",
    "# Using cv2.COLOR_BGR2GRAY color space\n",
    "# conversion code\n",
    "plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "# Using cv2.cvtColor() method\n",
    "# Using cv2.COLOR_BGR2HSV color space\n",
    "# conversion code\n",
    "plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2HSV))\n",
    "plt.show()\n",
    "# Convert from BGR to Grayscale\n",
    "gray_image = plt.imshow(cv.cvtColor(img1, cv.COLOR_BGR2GRAY))\n",
    "gray_image\n",
    "## The cv2.BORDER_REFLECT creates borders which is a mirror reflection of border elements like this:\n",
    "img = cv.imread(\"C:\\\\Users\\\\Savita Seharawat\\\\Desktop\\\\cvi620\\\\week 2\\\\project.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "REFLECT=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_REFLECT)\n",
    "plt.imshow(REFLECT)\n",
    "plt.show()\n",
    "\n",
    "REPLICATE=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_REPLICATE)\n",
    "plt.imshow(REPLICATE)\n",
    "plt.show()\n",
    "WRAP=cv.copyMakeBorder(img,50,50,50,50,cv.BORDER_WRAP)\n",
    "plt.imshow(WRAP)\n",
    "plt.show()\n",
    "REFLECT=cv.copyMakeBorder(img1,550,550,550,550,cv.BORDER_REFLECT)\n",
    "plt.imshow(REFLECT)\n",
    "plt.show()\n",
    "WRAP=cv.copyMakeBorder(img1,550,550,550,550,cv.BORDER_WRAP)\n",
    "plt.imshow(WRAP)\n",
    "plt.show()\n",
    "\n",
    "replicate=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REPLICATE)\n",
    "reflect=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REFLECT)\n",
    "reflect101=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_REFLECT_101)\n",
    "wrap=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_WRAP)\n",
    "constant=cv.copyMakeBorder(img1,bsz,bsz,bsz,bsz,cv.BORDER_CONSTANT,value=BLUE)\n",
    "plt.subplot(231), plt.imshow(cv.cvtColor(img1,cv.COLOR_BGR2RGB)), plt.title('ORIGINAL')\n",
    "plt.subplot(232), plt.imshow(cv.cvtColor(replicate,cv.COLOR_BGR2RGB)), plt.title('REPLICATE')\n",
    "plt.subplot(233), plt.imshow(cv.cvtColor(reflect,cv.COLOR_BGR2RGB)), plt.title('REFLECT')\n",
    "plt.subplot(234), plt.imshow(cv.cvtColor(reflect101,cv.COLOR_BGR2RGB)), plt.title('REFLECT_101')\n",
    "plt.subplot(235), plt.imshow(cv.cvtColor(wrap,cv.COLOR_BGR2RGB)), plt.title('WRAP')\n",
    "plt.subplot(236), plt.imshow(cv.cvtColor(constant,cv.COLOR_BGR2RGB)), plt.title('CONSTANT')\n",
    "plt.show()\n",
    "\n",
    "image = cv.imread(\"C:\\\\Users\\\\Savita Seharawat\\\\Desktop\\\\cvi620\\\\week 2\\\\cmyk_paint.png\") \n",
    "B, G, R = cv.split(image) \n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(image) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(B) \n",
    "plt.title(\"blue\")\n",
    "plt.show()\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(G) \n",
    "plt.title(\"Green\")\n",
    "plt.show()\n",
    "# Corresponding channels are separated  \n",
    "plt.imshow(R) \n",
    "plt.title(\"Red\")\n",
    "plt.show()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "image\n",
    "image.shape\n",
    "image[:,:,0]\n",
    "image[:,:,1]\n",
    "image[:,:,2]\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2Luv)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.COLOR_BGR2Luv\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =\"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2Luv)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2 \n",
    "Color_name = [i for i in dir(cv2) if i.startswith('COLOR_BGR2')]\n",
    "print( Color_name )\n",
    "Color_name = [ cv2.COLOR_BGR2Luv, cv2.COLOR_BGR2GRAY,cv2.COLOR_BGR2LUV,cv2.COLOR_BGR2YCrCb,cv2.COLOR_BGR2Lab,cv2.COLOR_BGR2HLS_FULL]\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "for color_number in Color_name:\n",
    "    color_image = cv2.cvtColor(image,color_number)\n",
    "    cv2.imshow(f\"image *{color_number}*\", color_image)\n",
    "    cv2.waitKey(2000) # pause for 2 seconds\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "image.shape\n",
    "image.dtype\n",
    "np.ones(image.shape)\n",
    "np.uint8(np.ones(image.shape))\n",
    "# Make Make darker\n",
    "img_path = \"DogandCat.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "img2 = cv2.subtract(image ,np.uint8(np.ones(image.shape))*50)\n",
    "image = cv2.resize(img2, (1280, 720))\n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Make brighter\n",
    "img_path = \"DogandCat.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "img2 = cv2.add(image ,np.uint8(np.ones(image.shape))*200)\n",
    "image = cv2.resize(img2, (1280, 720))\n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Multiply & Divide (scalar)\n",
    "# Make brighter\n",
    "img_path = \"DogandCat.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "img2 = cv2.multiply(image ,np.uint8(np.ones(image.shape)),scale =0.5)\n",
    "image = cv2.resize(img2, (1280, 720))\n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Make brighter\n",
    "img_path = \"DogandCat.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "img2 = cv2.multiply(image ,np.uint8(np.ones(image.shape)),scale =1.5)\n",
    "image = cv2.resize(img2, (1280, 720))\n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Draw Rectangle on Image of dog\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "pt1 = (100, 150)\n",
    "pt2 = (410, 400)\n",
    "color = (0, 0, 255)\n",
    "thickness = 4\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#rectangle(img, pt1, pt2, color, thickness, lineType, shift)\n",
    "img_rect = cv2.rectangle(image, pt1, pt2, color, thickness, lineType)\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", img_rect)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Fill Rectangle on Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "pt1 = (100, 150)\n",
    "pt2 = (410, 400)\n",
    "color = (255, 0, 0)\n",
    "thickness = -1\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img_rect = cv2.rectangle(image, pt1, pt2, color, thickness, lineType)\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", img_rect)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Text On Rectangle on Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "pt1 = (100, 150)\n",
    "pt2 = (410, 400)\n",
    "color = (255, 0, 0)\n",
    "thickness = -1\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img_rect = cv2.rectangle(image, pt1, pt2, color, thickness, lineType)\n",
    " \n",
    "#text on image\n",
    "text = \"Face - 100%\"\n",
    "org = (150, 300)\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (0,0,25)\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#text, org, fontFace, fontScale, color[, thickness\n",
    " \n",
    "img_text = cv2.putText(img_rect, text, org, fontFace, fontScale, color, lineType)\n",
    " \n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Text Above Rectangle on Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "pt1 = (100, 150)\n",
    "pt2 = (410, 400)\n",
    "color = (255, 0, 0)\n",
    "thickness = 4\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img_rect = cv2.rectangle(image, pt1, pt2, color, thickness, lineType)\n",
    " \n",
    "#text on image\n",
    "text = \"Face - 100%\"\n",
    "org = (150, 140)\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (0,255,25)\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#text, org, fontFace, fontScale, color[, thickness\n",
    " \n",
    "img_text = cv2.putText(img_rect, text, org, fontFace, fontScale, color, lineType)\n",
    " \n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Save image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "pt1 = (100, 150)\n",
    "pt2 = (410, 400)\n",
    "color = (255, 0, 0)\n",
    "thickness = 4\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img_rect = cv2.rectangle(image, pt1, pt2, color, thickness, lineType)\n",
    " \n",
    "#text on image\n",
    "text = \"Face - 100%\"\n",
    "org = (150, 140)\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (0,255,25)\n",
    "lineType = cv2.LINE_4\n",
    " \n",
    "#text, org, fontFace, fontScale, color[, thickness\n",
    " \n",
    "img_text = cv2.putText(img_rect, text, org, fontFace, fontScale, color, lineType)\n",
    " \n",
    " \n",
    "cv2.imwrite(\"image_with_rect_text.png\", img_text)\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## How to write Text on Image?\n",
    "\"\"\"! Only a subset of Hershey fonts\n",
    "enum HersheyFonts {\n",
    "    FONT_HERSHEY_SIMPLEX        = 0, //!< normal size sans-serif font\n",
    "    FONT_HERSHEY_PLAIN          = 1, //!< small size sans-serif font\n",
    "    FONT_HERSHEY_DUPLEX         = 2, //!< normal size sans-serif font (more complex than FONT_HERSHEY_SIMPLEX)\n",
    "    FONT_HERSHEY_COMPLEX        = 3, //!< normal size serif font\n",
    "    FONT_HERSHEY_TRIPLEX        = 4, //!< normal size serif font (more complex than FONT_HERSHEY_COMPLEX)\n",
    "    FONT_HERSHEY_COMPLEX_SMALL  = 5, //!< smaller version of FONT_HERSHEY_COMPLEX\n",
    "    FONT_HERSHEY_SCRIPT_SIMPLEX = 6, //!< hand-writing style font\n",
    "    FONT_HERSHEY_SCRIPT_COMPLEX = 7, //!< more complex variant of FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "    FONT_ITALIC                 = 16 //!< flag for italic font\n",
    "};\"\"\"\n",
    "## Line STyle\n",
    "cv::LineTypes {\n",
    "  cv::FILLED = -1,\n",
    "  cv::LINE_4 = 4,\n",
    "  cv::LINE_8 = 8,\n",
    "  cv::LINE_AA = 16\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\cvi620\\week 2\\testfolder\\160 cm kingsize bed.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "text = \"Model\"\n",
    "org = (100, 200)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "fontScale = 6\n",
    "color = (0,0,255)  #(B, G, R)\n",
    "thickness = 3\n",
    "lineType = cv2.LINE_AA\n",
    "bottomLeftOrigin = False\n",
    " \n",
    "# Syntax>> cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    " \n",
    "img_text = cv2.putText(image, text, org, font, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    " \n",
    "cv2.imshow(\"Text Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\cvi620\\week 2\\testfolder\\160 cm kingsize bed.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "text = \"Model\"\n",
    "org = (100, 200)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "fontScale = 6\n",
    "color = (0,0,255)  #(B, G, R)\n",
    "thickness = 3\n",
    "lineType = cv2.LINE_AA\n",
    "bottomLeftOrigin = True\n",
    " \n",
    "# Syntax>> cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    " \n",
    "img_text = cv2.putText(image, text, org, font, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    " \n",
    "cv2.imshow(\"Text Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\cvi620\\week 2\\testfolder\\160 cm kingsize bed.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "text = \"Model\"\n",
    "org = (100, 200)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "fontScale = 6\n",
    "color = (0,0,255)  #(B, G, R)\n",
    "thickness = 3\n",
    "lineType = cv2.LINE_AA\n",
    "bottomLeftOrigin = False\n",
    " \n",
    "# Syntax>> cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    " \n",
    "img_text = cv2.putText(image, text, org, font, fontScale, color, thickness, lineType, bottomLeftOrigin)\n",
    "img_text = cv2.putText(img_text, text, org, font, fontScale, color, thickness, lineType, bottomLeftOrigin = True)\n",
    " \n",
    "cv2.imshow(\"Text Image\", img_text)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## Color Pixels Extraction\n",
    "## How to Detect Road Marking Using OpenCV\n",
    "# Show an Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =\"road.png\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    " \n",
    "cv2.imshow(\"Road Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Conver image in gray scale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "cv2.imshow(\"Gray Image\", gray_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Road Margin Detection using Gray Image\n",
    "gray_img_copy = np.copy(gray_image)\n",
    " \n",
    "gray_img_copy[gray_img_copy[:, :] < 100]=0\n",
    " \n",
    "cv2.imshow(\"Gray Image\", gray_img_copy)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    " ## 0 - 255 ## 0=Black, 255= White\n",
    " \n",
    "gray_img_copy[:, :] < 140\n",
    " \n",
    "gray_img_copy\n",
    " \n",
    "\n",
    "img_path =\"road1.png\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (1280, 720))\n",
    " \n",
    "img_copy = np.copy(img)\n",
    " \n",
    "img_copy[(img_copy[:,:,0] > 50) | (img_copy[:,:,1] < 100) | (img_copy[:, :, 2] < 150) ]=0\n",
    " \n",
    "img_2 = np.hstack((cv2.resize(img, (650, 500)), cv2.resize(img_copy, (650, 500))))\n",
    "cv2.imshow(\"Yellow Road Image\", img_2)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "img_path =r\"red_road.png\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (1280, 720))\n",
    " \n",
    "img_copy = np.copy(img)\n",
    " \n",
    "img_copy[(img_copy[:,:,0] > 60) | (img_copy[:,:,1] > 60) | (img_copy[:, :, 2] < 80) ]=0\n",
    " \n",
    "img_2 = np.hstack(( cv2.resize(img, (500, 500)), cv2.resize(img_copy, (500, 500)) ))\n",
    "cv2.imshow(\"Color Image VS Color Extracted Image\", img_2)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = \"DogandCat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "image\n",
    "image.shape\n",
    "image[:,:,0]\n",
    "image[:,:,1]\n",
    "image[:,:,2]\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2Luv)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.COLOR_BGR2Luv\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2Luv)\n",
    "cv2.imshow(\"Rectangle on Image\", img_gray)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2 \n",
    "Color_name = [i for i in dir(cv2) if i.startswith('COLOR_BGR2')]\n",
    "print( Color_name )\n",
    "Color_name = [ cv2.COLOR_BGR2Luv, cv2.COLOR_BGR2GRAY,cv2.COLOR_BGR2LUV,cv2.COLOR_BGR2YCrCb,cv2.COLOR_BGR2Lab,cv2.COLOR_BGR2HLS_FULL]\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path = r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "for color_number in Color_name:\n",
    "    color_image = cv2.cvtColor(image,color_number)\n",
    "    cv2.imshow(f\"image *{color_number}*\", color_image)\n",
    "    cv2.waitKey(2000) # pause for 2 seconds\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "img_path = \"red_road.png\"\n",
    " \n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.resize(image, (1280, 720))\n",
    "\n",
    " \n",
    "cv2.imshow(\"Rectangle on Image\", image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "image\n",
    "image.ravel()\n",
    "image.ravel().shape\n",
    "image.ravel().size\n",
    "import matplotlib.pyplot as plt\n",
    "# ## Histogram of Image \n",
    "\n",
    "plt.hist(image.ravel(), bins=256, range = [0,255])\n",
    "plt.show()\n",
    "# ## Histogram of All channels\n",
    "# In[8]:\n",
    "colors = ('b', 'g', 'r')\n",
    " \n",
    "img_ravel = [image[:, :, 0].ravel(), image[:, :, 1].ravel(), image[:,:, 2].ravel()] \n",
    "plt.hist(img_ravel, color=colors, label=colors)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# ## Histogram of All channels\n",
    "# In[8]:\n",
    "colors = ('b', 'g', 'r')\n",
    " \n",
    "img_ravel = [image[:, :, 0].ravel(), image[:, :, 1].ravel(), image[:,:, 2].ravel()] \n",
    "plt.hist(img_ravel, color=colors, label=colors,bins=256, range=[0,256])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "l1 = [\"eat\", \"sleep\", \"repeat\"]\n",
    "\n",
    "# printing the tuples in object directly\n",
    "for ele in enumerate(l1):\n",
    "    print (ele)\n",
    "# getting desired output from tuple\n",
    "for count, ele in enumerate(l1):\n",
    "    print(count)\n",
    "    print(ele)\n",
    "\n",
    " \n",
    "# ## Plot of all Channel using cv2.calcHist() Function\n",
    "\n",
    "colors = ('b', 'g', 'r')      \n",
    "plt.figure(figsize=(16, 9))\n",
    "for i, color in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "    plt.plot(histogram, color=color)\n",
    "plt.show()\n",
    "\n",
    "## Blur Image using filter2d OpenCV Python\n",
    "## cv2.filter2D(src, ddepth, kernel, dst, anchor, delta, borderType) -> dst\n",
    "\n",
    "## Parameters:\n",
    "## src input image.\n",
    "## dst output image of the same size and the same number of channels as src.\n",
    "##  ddepth desired depth of the destination image, see @ref filter_depths \"combinations\"\n",
    "## kernel convolution kernel (or rather a correlation kernel), a single-channel floating point matrix; if you want to apply different kernels to different channels, split the image into\n",
    "## separate color planes using split and process them individually.\n",
    "## anchor anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor\n",
    "## is at the kernel center.\n",
    "## delta optional value added to the filtered pixels before storing them in dst.\n",
    "## borderType pixel extrapolation method, see #BorderTypes\n",
    "## sa  sepFilter2D, dft, matchTemplate\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =\"DogandCat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "one_mat_3_3 = np.ones((3,3), dtype=np.float32)/9\n",
    "blur_img_3_3 = cv2.filter2D(img, -1, one_mat_3_3)\n",
    " \n",
    " \n",
    "cv2.imshow(\"Blure image 3x3\", blur_img_3_3)\n",
    "## cv2.imshow(\"Original Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using Filter2D with 5×5 kernel\n",
    "one_mat_5_5 = np.ones((5,5), dtype=np.float32)/25\n",
    "blur_img_5_5 = cv2.filter2D(img, -1, one_mat_5_5)\n",
    " \n",
    " \n",
    "cv2.imshow(\"Blure image 5x5\", blur_img_5_5)\n",
    "## cv2.imshow(\"Original Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using Filter2D with 10×10 kernel\n",
    "# 10*10\n",
    "one_mat_10_10 = np.ones((10,10), dtype=np.float32)/100\n",
    " \n",
    "blur_img_10_10 = cv2.filter2D(img, -1, one_mat_10_10)\n",
    " \n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Blure Image using\", blur_img_10_10)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using Filter2D with 50×50 kernel\n",
    "# 50*50\n",
    "one_mat_50_50 = np.ones((50,50), dtype=np.float32)/2500\n",
    " \n",
    "blur_img_50_50 = cv2.filter2D(img, -1, one_mat_50_50)\n",
    " \n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Blure Image using\", blur_img_50_50)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using Filter2D with 100×100 kernel\n",
    "# 100*100\n",
    "one_mat_100_100 = np.ones((100,100), dtype=np.float32)/10000\n",
    " \n",
    "blur_img_100_100 = cv2.filter2D(img, -1, one_mat_100_100)\n",
    " \n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Blure Image using\", blur_img_100_100)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Show All Result in Single Windows(Image)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "blur_img_3_3 = cv2.resize(blur_img_3_3, (400, 350))\n",
    "blur_img_5_5 = cv2.resize(blur_img_5_5, (400, 350))\n",
    "blur_img_10_10 = cv2.resize(blur_img_10_10, (400, 350))\n",
    "blur_img_50_50 = cv2.resize(blur_img_50_50, (400, 350))\n",
    "blur_img_100_100 = cv2.resize(blur_img_100_100, (400, 350))\n",
    " \n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.putText(blur_img_3_3, \"3x3 Filter\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(blur_img_5_5, \"5x5 Filter\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(blur_img_10_10, \"10x10 Filter\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(blur_img_50_50, \"50x50 Filter\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(blur_img_100_100, \"100x100 Filter\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    " \n",
    "img1_3 = np.hstack((img, blur_img_3_3, blur_img_5_5))\n",
    "img2_3 = np.hstack((blur_img_10_10, blur_img_50_50,blur_img_100_100))\n",
    " \n",
    "img3_6 = np.vstack((img1_3,img2_3))\n",
    " \n",
    "cv2.imshow(\"1 original and 5 Blur Image\", img3_6)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "![image.png](attachment:8a7d5db2-8eee-44b4-92aa-11d4a50e5215.png)\n",
    "![image.png](attachment:827277b2-546b-4adc-970f-b52898122bd0.png)\n",
    "![image.png](attachment:bcdd7d41-2cf3-4f1c-942a-88329d285b01.png)\n",
    "## Blur Image Using cv2.blur() & cv2.boxFilter()OpenCV Python\n",
    "## cv2.blur(src, ksize, ds[, anchor, borderType) -> dst\n",
    "## Blur Image using cv2.blur() with Kernel 3×3\n",
    "img_blur_3 = cv2.blur(img, (3,3))\n",
    " \n",
    "cv2.imshow(\"Model Blur\", img_blur_3)\n",
    "cv2.imshow(\"Model \", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using cv2.blur() with Kernel 50×50\n",
    "img_blur_50 = cv2.blur(img, (50,50))\n",
    " \n",
    "cv2.imshow(\"Model Blur\", img_blur_50)\n",
    "cv2.imshow(\"Model \", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using cv2.boxfilter() with Kernel 3×3\n",
    "img_b_blur_3 = cv2.boxFilter(img, -1, (3,3))\n",
    "img_blur_3 = cv2.blur(img, (3,3))\n",
    " \n",
    "cv2.imshow(\"Model Blur\", img_b_blur_3)\n",
    "cv2.imshow(\"Model \", img_blur_3)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image using cv2.boxfilter() with Kernel 50×50\n",
    "img_b_blur_50 = cv2.boxFilter(img, -1, (50,50),normalize = False)\n",
    " \n",
    "cv2.imshow(\"Model Blur\", img_b_blur_50)\n",
    "cv2.imshow(\"Model \", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import numpy as np\n",
    " \n",
    "img_blur_3 = cv2.resize(img_blur_3, (650, 400))\n",
    "img_blur_50 = cv2.resize(img_blur_50, (650, 400))\n",
    " \n",
    "img_b_blur_3 = cv2.resize(img_b_blur_3, (650, 400))\n",
    "img_b_blur_50 = cv2.resize(img_b_blur_50, (650, 400))\n",
    " \n",
    "#putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "cv2.putText(img_blur_3, \"blur 3x3\", (10,50), cv2.FONT_HERSHEY_COMPLEX, 2, (255,0,55), 3)\n",
    "cv2.putText(img_blur_50, \"blur 50x50\", (10,50), cv2.FONT_HERSHEY_COMPLEX, 2, (255,0,55), 3)\n",
    "cv2.putText(img_b_blur_3, \"box blur 3x3\", (10,50), cv2.FONT_HERSHEY_COMPLEX, 2, (255,255, 0), 3)\n",
    "cv2.putText(img_b_blur_50, \"box blur 50x50\", (10,50), cv2.FONT_HERSHEY_COMPLEX, 2, (255,255, 0), 3)\n",
    " \n",
    " \n",
    "blurr_2_img = np.hstack((img_blur_3, img_blur_50))\n",
    "filter_blur_2_img = np.hstack((img_b_blur_3, img_b_blur_50))\n",
    " \n",
    "img_4 = np.vstack((blurr_2_img, filter_blur_2_img))\n",
    " \n",
    "cv2.imshow(\"Show 4 Blur Image\", img_4)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "## Blur Image in 2 Line\n",
    "import cv2\n",
    " \n",
    "cv2.imshow(\"Blur Image\", cv2.blur(cv2.imread(r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"), (50,50)))\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Managing the imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#reading a image from computer and taking dimensions\n",
    "img = cv2.imread('nature.jpg')\n",
    "img = cv2.resize(img,(400,400))\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "#Kernel Blurring using filter2D()\n",
    "kernel_25 = np.ones((25,25), np.float32) / 625.0\n",
    "output_kernel = cv2.filter2D(img, -1, kernel_25)\n",
    "\n",
    "#Boxfilter and blur function blurring\n",
    "output_blur = cv2.blur(img, (25,25))\n",
    "output_box = cv2.boxFilter(img, -1, (5,5), normalize=False)\n",
    "\n",
    "#gaussian Blur \n",
    "output_gaus = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "#median Bur (reduction of noise)\n",
    "output_med = cv2.medianBlur(img, 5)\n",
    "\n",
    "#Bilateral filtering (Reduction of noise + Preserving of edges)\n",
    "\n",
    "output_bil = cv2.bilateralFilter(img, 5, 6, 6)\n",
    "\n",
    "\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2, color=(255,0,255) )\n",
    "cv2.putText(output_kernel, \"kernel blur\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_blur, \"Blur() output\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_box, \"output_box\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_gaus, \"Gaussian\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_bil, \"Bilateral\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_med, \"Median Blur\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "\n",
    "img1_3 = np.hstack((img,img, output_kernel, output_blur))\n",
    "img2_3 = np.hstack((output_box, output_gaus,output_bil,output_med))\n",
    " \n",
    "img3_6 = np.vstack((img1_3,img2_3))\n",
    " \n",
    "cv2.imshow(\"1 original and 5 Blur Image\", img3_6)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#Managing the imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#reading a image from computer and taking dimensions\n",
    "img = cv2.imread('noisy.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "#Kernel Blurring using filter2D()\n",
    "kernel_25 = np.ones((25,25), np.float32) / 625.0\n",
    "output_kernel = cv2.filter2D(img, -1, kernel_25)\n",
    "\n",
    "#Boxfilter and blur function blurring\n",
    "output_blur = cv2.blur(img, (25,25))\n",
    "output_box = cv2.boxFilter(img, -1, (5,5), normalize=False)\n",
    "\n",
    "#gaussian Blur \n",
    "output_gaus = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "#median Bur (reduction of noise)\n",
    "output_med = cv2.medianBlur(img, 5)\n",
    "\n",
    "#Bilateral filtering (Reduction of noise + Preserving of edges)\n",
    "\n",
    "output_bil = cv2.bilateralFilter(img, 5, 6, 6)\n",
    "\n",
    "\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2, color=(255,0,255) )\n",
    "cv2.putText(output_kernel, \"kernel blur\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_blur, \"Blur() output\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_box, \"output_box\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_gaus, \"Gaussian\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_bil, \"Bilateral\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(output_med, \"Median Blur\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "\n",
    "img1_3 = np.hstack((img,img, output_kernel, output_blur))\n",
    "img2_3 = np.hstack((output_box, output_gaus,output_bil,output_med))\n",
    " \n",
    "img3_6 = np.vstack((img1_3,img2_3))\n",
    " \n",
    "cv2.imshow(\"1 original and 5 Blur Image\", img3_6)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# What is Convoluation\n",
    "# Conolution is a fundamental operation in the image processing.We basically apply a mathematical operator to each pixcel and change its value in some way.\n",
    "# To apply this mathematical operator, we use another matrix called a kernel.\n",
    "# The Kernel is fixed with its center on each pixel, and corresponding pixelsare multiplied. The pixel value is replaced with sum of all multiplication.\n",
    "![image.png](attachment:756739fc-81e3-4a39-9238-a8ef79b41e74.png)\n",
    "# High Pass and Low pass Filters\n",
    "# High Pass and Low pass Filters\n",
    "# What is frequency in image\n",
    "# High Pass and Low pass Filters\n",
    "# What is frequency in image\n",
    "# Frequency refers to the rate of change of pixel values.So we can say that the sharp edges would be high frequency content \n",
    "# because the pixel values change rapidly in that region. Going by that logic,plain areas would be low frequency content.\n",
    "![image.png](attachment:25f975d5-5809-4817-8f2a-74487eaba0eb.png)\n",
    "# High Pass and Low pass Filters\n",
    "# What is frequency in image\n",
    "# Frequency refers to the rate of change of pixel values.So we can say that the sharp edges would be high frequency content \n",
    "# because the pixel values change rapidly in that region. Going by that logic,plain areas would be low frequency content.\n",
    "# Low pass filter is the type of frequency domain filter that reduces the high frequency components and preserves the low frequency components.\n",
    "# High Pass and Low pass Filters\n",
    "# What is frequency in image\n",
    "# Frequency refers to the rate of change of pixel values.So we can say that the sharp edges would be high frequency content \n",
    "# because the pixel values change rapidly in that region. Going by that logic,plain areas would be low frequency content.\n",
    "# Low pass filter is the type of frequency domain filter that reduces the high frequency components and preserves the low frequency components.\n",
    "#  High pass filter is the type of frequency domain filter that reduces the low  frequency components and preserves the high frequency components.\n",
    "# High Pass and Low pass Filters\n",
    "# What is frequency in image\n",
    "# Frequency refers to the rate of change of pixel values.So we can say that the sharp edges would be high frequency content \n",
    "# because the pixel values change rapidly in that region. Going by that logic,plain areas would be low frequency content.\n",
    "# Low pass filter is the type of frequency domain filter that reduces the high frequency components and preserves the low frequency components.\n",
    "#  High pass filter is the type of frequency domain filter that reduces the low  frequency components and preserves the high frequency components.\n",
    "# The Kernel is called the 'image filter\" and the process of applying this kernel to the given image is called \"image filtering'. The output obtained after applying the kernel to the image is called the Filtered image.\n",
    "#importing the modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Import the image\n",
    "img = cv2.imread('nature.jpg')\n",
    "cv2.imshow('same', img)\n",
    "#cv2.imshow('3 blur', output2)\n",
    "#cv2.imshow('11 blur', output3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#importing the modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Import the image\n",
    "img = cv2.imread('nature.jpg')\n",
    "\n",
    "#Form the filters\n",
    "kernel_identity = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "kernel_3  = np.ones((3,3), dtype=np.float32) / 9.0\n",
    "kernel_11 = np.ones((11,11), dtype=np.float32) / 121.0\n",
    "\n",
    "#Applyt the filters\n",
    "output1 = cv2.filter2D(img,-1,kernel_identity)\n",
    "output2 = cv2.filter2D(img, -1, kernel_3)\n",
    "output3 = cv2.filter2D(img,-1 , kernel_11)\n",
    "\n",
    "#Show the image\n",
    "cv2.imshow('same', output1)\n",
    "cv2.imshow('3 blur', output2)\n",
    "cv2.imshow('11 blur', output3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# MOTION BLURRING\n",
    "## In filter, the values indicate the direction of the gradients to be judged for.\n",
    "![image.png](attachment:5b1c4a54-12cd-4fab-9e05-95447e584f25.png)\n",
    "# A directional Low-Pass Filter\n",
    "img = cv2.imread('nature.jpg')\n",
    "size = 15\n",
    "\n",
    "kernel = np.zeros((size,size))\n",
    "kernel[int((size)/2),:] = np.ones(size)\n",
    "kernel = kernel/size\n",
    "print(kernel[0])\n",
    "\n",
    "output  = cv2.filter2D(img, -1, kernel)\n",
    "cv2.imshow('winname', output)\n",
    "cv2.imshow('winnam1e', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "img = cv2.rotate(img,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "img = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "img = cv2.rotate(img,cv2.ROTATE_180)\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Show Image\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img_path =r\"C:\\Users\\Savita Seharawat\\Desktop\\fulhaus\\Dog+and+Cat.jpg\"\n",
    " \n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (400, 350))\n",
    "h,w =img.shape[0:2]\n",
    "centre = (h/2,w/2)\n",
    "rot = cv2.getRotationMatrix2D(centre,45,1)\n",
    "img = cv2.warpAffine(img,rot,(300,400))\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(0,0,255))\n",
    "cv2.imshow(\"Model Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Getting the imports \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Reading the image\n",
    "img = cv2.imread('nature.jpg')\n",
    "\n",
    "#Gauusian kernel for sharpening\n",
    "gaussian_blur = cv2.GaussianBlur(img, (7,7), 2)\n",
    "\n",
    "#Sharpening using addweighted()\n",
    "sharpened1 = cv2.addWeighted(img,1.5, gaussian_blur, -0.5, 0)\n",
    "sharpened2 = cv2.addWeighted(img,3.5, gaussian_blur, -2.5, 0)\n",
    "sharpened3 = cv2.addWeighted(img,7.5, gaussian_blur, -6.5, 0)\n",
    "\n",
    "img = cv2.resize(img, (500, 300))\n",
    "sharpened1 = cv2.resize(sharpened1, (500, 300))\n",
    "sharpened2 = cv2.resize(sharpened2, (500, 300))\n",
    "sharpened3 = cv2.resize(sharpened3, (500, 300))\n",
    "\n",
    "\n",
    "cv2.putText(img, \"Original\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2, color=(255,0,255) )\n",
    "cv2.putText(sharpened1, \"sharpened1\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(sharpened2, \"sharpened2\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "cv2.putText(sharpened3, \"sharpened3\", org=(20,40), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale= 2 , color=(255,0,255))\n",
    "\n",
    "\n",
    "img1_3 = np.hstack((img, sharpened1))\n",
    "img2_3 = np.hstack((sharpened2,sharpened3))\n",
    " \n",
    "img3_6 = np.vstack((img1_3,img2_3))\n",
    " \n",
    "cv2.imshow(\"sharpening\", img3_6)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Fixing the imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#-----------------Phase 1\n",
    "#Readin the image\n",
    "image = cv2.imread('profile.jpeg')\n",
    "image = cv2.resize(image, (400, 300))\n",
    "\n",
    "#resizing the image\n",
    "#Interpolation is cubic for best results\n",
    "image_resized = cv2.resize(image, None, fx=1.5, fy=1.5)\n",
    "\n",
    "\n",
    "\n",
    "#-----------------Phase 2\n",
    "#removing impurities from image\n",
    "image_cleared = cv2.medianBlur(image_resized, 3)\n",
    "image_cleared = cv2.medianBlur(image_cleared, 3)\n",
    "image_cleared = cv2.medianBlur(image_cleared, 3)\n",
    "\n",
    "image_cleared = cv2.edgePreservingFilter(image_cleared, sigma_s=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-----------------Phase 3\n",
    "#Bilateral Image filtering \n",
    "image_filtered = cv2.bilateralFilter(image_cleared, 3, 10, 5)\n",
    "\n",
    "for i in range(2):\n",
    "    image_filtered = cv2.bilateralFilter(image_filtered, 3, 20, 10)\n",
    "\n",
    "for i in range(3):\n",
    "    image_filtered = cv2.bilateralFilter(image_filtered, 5, 30, 10)\n",
    "\n",
    "for i in range(3):\n",
    "\timage_filtered = cv2.bilateralFilter(image_filtered, 5, 40, 10)\n",
    "\n",
    "for i in range(2):\n",
    "\timage_filtered = cv2.bilateralFilter(image_filtered, 3, 40, 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------Phase 4\n",
    "#Sharpening the image using addWeighted()\n",
    "gaussian_mask= cv2.GaussianBlur(image_filtered, (7,7), 2)\n",
    "image_sharp = cv2.addWeighted(image_filtered, 1.5, gaussian_mask, -0.5, 0)\n",
    "image_sharp = cv2.addWeighted(image_sharp, 1.4, gaussian_mask, -0.2, 10)\n",
    "\n",
    "horizontal_stack = cv2.hconcat([image_resized, image_cleared, image_sharp])\n",
    "\n",
    "\n",
    "#displayng images\n",
    "cv2.imshow('Final Image', horizontal_stack)\n",
    "# cv2.imshow('Clear impurities', image_cleared)\n",
    "# cv2.imshow('original', image_resized)\n",
    "#cv2.imwrite('art_test1.jpg', image_sharp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Fixing the imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# -----------------Phase 1\n",
    "# Reading the image\n",
    "image = cv2.imread('profile.jpeg')\n",
    "image = cv2.resize(image, (400, 300))\n",
    "\n",
    "# Resizing the image\n",
    "# Interpolation is cubic for best results\n",
    "image_resized = cv2.resize(image, None, fx=1.5, fy=1.5)\n",
    "\n",
    "# -----------------Phase 2\n",
    "# Removing impurities from the image using Edge-Preserving Filter\n",
    "image_cleared = cv2.edgePreservingFilter(image_resized, flags=1, sigma_s=60, sigma_r=0.4)\n",
    "\n",
    "# -----------------Phase 3\n",
    "# Applying bilateral filter to create the watercolor effect\n",
    "for i in range(2):\n",
    "    image_filtered = cv2.bilateralFilter(image_cleared, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "# -----------------Phase 4\n",
    "# Sharpening the image to emphasize edges\n",
    "gaussian_mask = cv2.GaussianBlur(image_filtered, (7, 7), 2)\n",
    "image_sharp = cv2.addWeighted(image_filtered, 1.5, gaussian_mask, -0.5, 0)\n",
    "\n",
    "# -----------------Phase 5\n",
    "# Creating a horizontal stack that includes all images: original resized, cleared, and sharp (watercolor-like)\n",
    "horizontal_stack = cv2.hconcat([image_resized, image_cleared, image_sharp])\n",
    "\n",
    "# Display the final result\n",
    "cv2.imshow('Watercolor Effect', horizontal_stack)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "original = cv2.imread('Media.jpeg')\n",
    " \n",
    "if original is None:\n",
    "    print('Could not open or find the image')\n",
    "    sys.exit()\n",
    " \n",
    "original = cv2.resize(original, (400, 400))\n",
    "\n",
    "if len(original.shape) == 3:\n",
    "    original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# original=cv2.cvtColor(original, cv2.COLOR_GRAY2BGR)\n",
    " \n",
    "g_sobelx = cv2.Sobel(original, -1, 1, 0)\n",
    "g_sobely = cv2.Sobel(original, -1, 0, 1)\n",
    "g_combined = cv2.addWeighted(g_sobelx, 0.9, g_sobely, 0.7, 0)\n",
    "g_lap = cv2.Laplacian(original, -5)\n",
    "canny = cv2.Canny(original, 90, 150)\n",
    "\n",
    " \n",
    "def add_label(image, text, position=(10, 30), font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=1, color=(255, 255, 255), thickness=2):\n",
    "    cv2.putText(image, text, position, font, font_scale, color, thickness)\n",
    " \n",
    "add_label(original, 'Original Image')\n",
    "add_label(g_sobelx, 'Sobel X')\n",
    "add_label(g_sobely, 'Sobel Y')\n",
    "add_label(g_combined, 'Sobel Combined')\n",
    "add_label(g_lap, 'Laplacian')\n",
    "add_label(canny, 'Canny Edge Detection')\n",
    " \n",
    "height, width = original.shape\n",
    "images = [original, g_sobelx, g_sobely, g_combined, g_lap, canny]\n",
    "images_resized = [cv2.resize(img, (width, height)) for img in images]\n",
    " \n",
    "top_row = np.hstack((images_resized[0], images_resized[1], images_resized[2]))\n",
    "bottom_row = np.hstack((images_resized[3], images_resized[4], images_resized[5]))\n",
    " \n",
    "stacked_images = np.vstack((top_row, bottom_row))\n",
    " \n",
    " \n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(stacked_images, (x, y), 50, (255, 255, 255), 4)\n",
    "        cv2.imshow('Stacked Images', stacked_images)\n",
    "cv2.imshow('Stacked Images', stacked_images)\n",
    "cv2.setMouseCallback('Stacked Images', draw_circle)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "images = {\n",
    "    \"Geometric Shapes - OpenCV\": \"images/geometric_shapes.jpg\",\n",
    "    \"Industrial Objects - OpenCV\": \"images/industrial_objects.jpg\",\n",
    "    \"Natural Scenes - OpenCV\": \"images/natural_scenes.jpg\",\n",
    "}\n",
    "\n",
    "# Task 1: Acquiring Sample Images\n",
    "for window_name, image_path in images.items():\n",
    "    image = cv.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        continue\n",
    "\n",
    "    cv.imshow(window_name, image)\n",
    "\n",
    "    # Task 2: Grayscale Conversion\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow(f\"Grayscale - {window_name}\", gray_image)\n",
    "\n",
    "    # Task 3: Noise Reduction Using Smoothing\n",
    "    gaussian_blur = cv.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    gray_image_3channel = cv.cvtColor(gray_image, cv.COLOR_GRAY2BGR)\n",
    "    gaussian_blur_3channel = cv.cvtColor(gaussian_blur, cv.COLOR_GRAY2BGR)\n",
    "    concatenated_image = cv.hconcat(\n",
    "        [image, gray_image_3channel, gaussian_blur_3channel]\n",
    "    )\n",
    "    cv.imshow(\n",
    "        f\"Original vs Grayscale vs Gaussian Blurred - {window_name}\", concatenated_image\n",
    "    )\n",
    "\n",
    "    # Task 4: Sobel Edge Detection\n",
    "    sobel_x = cv.Sobel(gaussian_blur, cv.CV_64F, 1, 0, ksize=5)\n",
    "    sobel_y = cv.Sobel(gaussian_blur, cv.CV_64F, 0, 1, ksize=5)\n",
    "    sobel_combined = cv.addWeighted(np.abs(sobel_x), 0.5, np.abs(sobel_y), 0.5, 0)\n",
    "    sobel_combined = np.uint8(sobel_combined)\n",
    "    cv.imshow(f\"Sobel Edge Detection - {window_name}\", sobel_combined)\n",
    "\n",
    "    # Task 5: Laplacian Edge Detection\n",
    "    laplacian = cv.Laplacian(gaussian_blur, cv.CV_64F)\n",
    "    laplacian = np.abs(laplacian)\n",
    "    laplacian = np.uint8(laplacian)\n",
    "    cv.imshow(f\"Laplacian Edge Detection - {window_name}\", laplacian)\n",
    "\n",
    "    # Task 7: Canny Edge Detection\n",
    "    canny_edges = cv.Canny(gaussian_blur, 100, 200)\n",
    "    cv.imshow(f\"Canny Edge Detection - {window_name}\", canny_edges)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
